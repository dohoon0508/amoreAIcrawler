"""
ì•„ëª¨ë ˆëª° ì œí’ˆ í›„ê¸° í¬ë¡¤ë§ ë° ë°ì´í„°ë² ì´ìŠ¤í™” ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸
"""
import argparse
import json
import os
import time
from crawler import AmoreMallCrawler
from summarizer import ReviewSummarizer
from database import DatabaseManager


def main():
    parser = argparse.ArgumentParser(description='ì•„ëª¨ë ˆëª° ì œí’ˆ í›„ê¸° í¬ë¡¤ë§ ë° ìš”ì•½')
    parser.add_argument('url', help='ì œí’ˆ í˜ì´ì§€ URL ë˜ëŠ” ë¸Œëœë“œ í˜ì´ì§€ URL')
    parser.add_argument('--max-pages', type=int, default=10, help='ìµœëŒ€ í˜ì´ì§€ ìˆ˜ (ê¸°ë³¸ê°’: 10, 0ì´ë©´ ëª¨ë“  í˜ì´ì§€)')
    parser.add_argument('--max-reviews', type=int, help='ìµœëŒ€ ë¦¬ë·° ìˆ˜ (ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ ì œí•œ ì—†ìŒ)')
    parser.add_argument('--brand', action='store_true', help='ë¸Œëœë“œ í˜ì´ì§€ ëª¨ë“œ (ëª¨ë“  ì œí’ˆ í¬ë¡¤ë§)')
    parser.add_argument('--max-products', type=int, help='ë¸Œëœë“œ ëª¨ë“œì—ì„œ ìµœëŒ€ ì œí’ˆ ìˆ˜')
    parser.add_argument('--headless', action='store_true', help='ë¸Œë¼ìš°ì €ë¥¼ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰')
    parser.add_argument('--use-openai', action='store_true', help='OpenAI APIë¥¼ ì‚¬ìš©í•œ ìš”ì•½ (ê¸°ë³¸ê°’: False)')
    parser.add_argument('--db-path', default='amoremall_reviews.db', help='ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--output', help='ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥í•  ê²½ë¡œ')
    parser.add_argument('--debug', action='store_true', help='ë””ë²„ê¹… ëª¨ë“œ (HTML ì €ì¥ ë“±)')
    parser.add_argument('--test', action='store_true', help='í…ŒìŠ¤íŠ¸ ëª¨ë“œ (ë” ë³´ê¸° ë²„íŠ¼ 3ë²ˆë§Œ í´ë¦­)')
    parser.add_argument('--max-more-clicks', type=int, help='ë” ë³´ê¸° ë²„íŠ¼ ìµœëŒ€ í´ë¦­ íšŸìˆ˜ (ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ test_modeì— ë”°ë¼ ìë™ ì„¤ì •)')
    
    args = parser.parse_args()
    
    print("=" * 60)
    print("ì•„ëª¨ë ˆëª° ì œí’ˆ í›„ê¸° í¬ë¡¤ë§ ì‹œì‘")
    print("=" * 60)
    
    # í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”
    crawler = AmoreMallCrawler(headless=args.headless, debug=args.debug)
    db = DatabaseManager(db_path=args.db_path)
    summarizer = ReviewSummarizer(use_openai=args.use_openai)
    
    try:
        if args.brand:
            # ë¸Œëœë“œ í˜ì´ì§€ ëª¨ë“œ: ëª¨ë“  ì œí’ˆ í¬ë¡¤ë§
            print("\n[ë¸Œëœë“œ ëª¨ë“œ] ë¸Œëœë“œì˜ ëª¨ë“  ì œí’ˆ ë¦¬ë·° í¬ë¡¤ë§ ì¤‘...")
            max_pages = None if args.max_pages == 0 else args.max_pages
            results, brand_name = crawler.crawl_brand_products(
                args.url,
                max_products=args.max_products,
                max_pages_per_product=max_pages,
                max_reviews_per_product=args.max_reviews,
                test_mode=args.test,
                max_more_clicks=args.max_more_clicks
            )
            
            if not results:
                print("ì˜¤ë¥˜: ì œí’ˆì„ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ í¬ë¡¤ë§ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                return
            
            # ëª¨ë“  ì œí’ˆì˜ ê²°ê³¼ë¥¼ ì €ì¥
            all_reviews_data = []
            total_reviews = 0
            
            for result in results:
                product_info = result['product_info']
                reviews = result['reviews']
                total_reviews += len(reviews)
                
                if reviews:
                    # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                    product = db.add_product(product_info)
                    db.add_reviews(product.id, reviews)
                    
                    # ìš”ì•½ ìƒì„±
                    summary_data = summarizer.summarize_reviews(
                        reviews,
                        product_info.get('product_name', '')
                    )
                    db.add_summary(product.id, summary_data)
                    
                    all_reviews_data.append({
                        'product_info': product_info,
                        'reviews': reviews,
                        'summary': summary_data
                    })
            
            print(f"\n{'='*60}")
            print(f"ë¸Œëœë“œ í¬ë¡¤ë§ ì™„ë£Œ")
            print(f"{'='*60}")
            print(f"ì´ ì œí’ˆ ìˆ˜: {len(results)}ê°œ")
            print(f"ì´ í›„ê¸° ìˆ˜: {total_reviews}ê°œ")
            
            # íŒŒì¼ëª… ê¸°ë³¸ê°’ ìƒì„± (ë¸Œëœë“œëª… ì‚¬ìš©)
            if args.output:
                # ì¶œë ¥ íŒŒì¼ëª…ì—ì„œ ë¸Œëœë“œëª… ì¶”ì¶œ (ì˜ˆ: "20251227_sulwhasoo" -> "sulwhasoo")
                base_name = args.output.replace('.json', '').split('_')[-1] if '_' in args.output else args.output.replace('.json', '')
            else:
                # í¬ë¡¤ëŸ¬ì—ì„œ ì¶”ì¶œí•œ ë¸Œëœë“œëª… ì‚¬ìš©
                base_name = brand_name if brand_name else f"brand_{time.strftime('%Y%m%d')}"
            
            # ì œí’ˆ ì •ë³´ë§Œ ì €ì¥
            info_file = f"info_{base_name}.json"
            all_products_info = []
            for result in results:
                product_info = result['product_info']
                all_products_info.append(product_info)
            
            info_data = {
                'brand_url': args.url,
                'crawled_at': time.strftime('%Y-%m-%d %H:%M:%S'),
                'total_products': len(results),
                'products': all_products_info
            }
            
            with open(info_file, 'w', encoding='utf-8') as f:
                json.dump(info_data, f, ensure_ascii=False, indent=2)
            
            # ë¦¬ë·°ë§Œ ì €ì¥
            review_file = f"review_{base_name}.json"
            all_reviews_list = []
            for result in results:
                product_info = result['product_info']
                reviews = result['reviews']
                for review in reviews:
                    # ê° ë¦¬ë·°ì— ì œí’ˆ ì½”ë“œ ì¶”ê°€ (ì°¸ì¡°ìš©)
                    review_with_product = review.copy()
                    review_with_product['product_code'] = product_info.get('product_code', '')
                    review_with_product['product_name'] = product_info.get('product_name', '')
                    all_reviews_list.append(review_with_product)
            
            review_data = {
                'brand_url': args.url,
                'crawled_at': time.strftime('%Y-%m-%d %H:%M:%S'),
                'total_reviews': total_reviews,
                'reviews': all_reviews_list
            }
            
            with open(review_file, 'w', encoding='utf-8') as f:
                json.dump(review_data, f, ensure_ascii=False, indent=2)
            
            print(f"\nâœ“ JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ:")
            print(f"  - ì œí’ˆ ì •ë³´: {info_file}")
            print(f"    - ì´ {len(results)}ê°œ ì œí’ˆ")
            print(f"    - íŒŒì¼ í¬ê¸°: {os.path.getsize(info_file) / 1024 / 1024:.2f} MB")
            print(f"  - ë¦¬ë·°: {review_file}")
            print(f"    - ì´ {total_reviews}ê°œ í›„ê¸°")
            print(f"    - íŒŒì¼ í¬ê¸°: {os.path.getsize(review_file) / 1024 / 1024:.2f} MB")
            return
        
        else:
            # ë‹¨ì¼ ì œí’ˆ ëª¨ë“œ
            print("\n[1ë‹¨ê³„] ì œí’ˆ í›„ê¸° í¬ë¡¤ë§ ì¤‘...")
            max_pages = None if args.max_pages == 0 else args.max_pages
            result = crawler.crawl_product_reviews(args.url, max_pages=max_pages, max_reviews=args.max_reviews, test_mode=args.test)
            
            if not result['product_info']:
                print("ì˜¤ë¥˜: ì œí’ˆ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            product_info = result['product_info']
            reviews = result['reviews']
            
            print(f"\nâœ“ ì œí’ˆëª…: {product_info.get('product_name', 'N/A')}")
            print(f"âœ“ ì œí’ˆ ì½”ë“œ: {product_info.get('product_code', 'N/A')}")
            print(f"âœ“ ì¶”ì¶œëœ í›„ê¸° ìˆ˜: {len(reviews)}")
            
            if not reviews:
                print("ê²½ê³ : í›„ê¸°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            # 2. ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
            print("\n[2ë‹¨ê³„] ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ ì¤‘...")
            product = db.add_product(product_info)
            print(f"âœ“ ì œí’ˆ ì €ì¥ ì™„ë£Œ (ID: {product.id})")
            
            db.add_reviews(product.id, reviews)
            print(f"âœ“ í›„ê¸° ì €ì¥ ì™„ë£Œ ({len(reviews)}ê°œ)")
            
            # 3. í›„ê¸° ìš”ì•½
            print("\n[3ë‹¨ê³„] í›„ê¸° ìš”ì•½ ì¤‘...")
            summary_data = summarizer.summarize_reviews(
                reviews, 
                product_info.get('product_name', '')
            )
            
            db.add_summary(product.id, summary_data)
            print("âœ“ ìš”ì•½ ì €ì¥ ì™„ë£Œ")
            
            # 4. í¬ë¡¤ë§ëœ í›„ê¸° ìƒì„¸ ì¶œë ¥
            print("\n" + "=" * 60)
            print("í¬ë¡¤ë§ëœ í›„ê¸° ëª©ë¡")
            print("=" * 60)
            
            # ì²˜ìŒ 10ê°œ í›„ê¸° ìƒì„¸ ì¶œë ¥
            display_count = min(10, len(reviews))
            print(f"\n[ì´ {len(reviews)}ê°œ í›„ê¸° ì¤‘ ì²˜ìŒ {display_count}ê°œ ë¯¸ë¦¬ë³´ê¸°]\n")
            
            for i, review in enumerate(reviews[:display_count], 1):
                print(f"\n{'â”€' * 60}")
                print(f"í›„ê¸° #{i}")
                print(f"{'â”€' * 60}")
                
                if review.get('username'):
                    print(f"ğŸ‘¤ ì‚¬ìš©ì: {review['username']}")
                if review.get('user_info'):
                    print(f"ğŸ“‹ ì •ë³´: {review['user_info']}")
                if review.get('rating'):
                    stars = 'â­' * review['rating'] + 'â˜†' * (5 - review['rating'])
                    print(f"â­ í‰ì : {stars} ({review['rating']}/5)")
                if review.get('option'):
                    print(f"ğŸ¨ ì˜µì…˜: {review['option']}")
                if review.get('review_type'):
                    print(f"ğŸ·ï¸  íƒ€ì…: {review['review_type']}")
                
                print(f"\nğŸ’¬ í›„ê¸° ë‚´ìš©:")
                review_text = review.get('review_text', '')
                # ê¸´ í…ìŠ¤íŠ¸ëŠ” ì¤„ë°”ê¿ˆ ì²˜ë¦¬
                if len(review_text) > 100:
                    words = review_text.split()
                    lines = []
                    current_line = []
                    current_length = 0
                    for word in words:
                        if current_length + len(word) + 1 > 80:
                            lines.append(' '.join(current_line))
                            current_line = [word]
                            current_length = len(word)
                        else:
                            current_line.append(word)
                            current_length += len(word) + 1
                    if current_line:
                        lines.append(' '.join(current_line))
                    print('\n'.join(f"   {line}" for line in lines))
                else:
                    print(f"   {review_text}")
            
            if len(reviews) > display_count:
                print(f"\n... ì™¸ {len(reviews) - display_count}ê°œì˜ í›„ê¸°ê°€ ë” ìˆìŠµë‹ˆë‹¤.")
            
            # 5. ìš”ì•½ ê²°ê³¼ ì¶œë ¥
            print("\n" + "=" * 60)
            print("ìš”ì•½ ê²°ê³¼")
            print("=" * 60)
            print(f"\nğŸ“Š í‰ê·  í‰ì : {summary_data['average_rating']}/5.0")
            print(f"ğŸ“ ì´ í›„ê¸° ìˆ˜: {summary_data['total_reviews']}ê°œ")
            print(f"ğŸ‘ ê¸ì •ì  í›„ê¸°: {summary_data['positive_count']}ê°œ")
            print(f"ğŸ‘ ë¶€ì •ì  í›„ê¸°: {summary_data['negative_count']}ê°œ")
            
            if summary_data['key_points']:
                print(f"\nğŸ”‘ ì£¼ìš” í¬ì¸íŠ¸:")
                for point in summary_data['key_points']:
                    print(f"   â€¢ {point}")
            
            print(f"\nğŸ“„ ì¢…í•© ìš”ì•½:")
            summary_text = summary_data['summary']
            # ìš”ì•½ í…ìŠ¤íŠ¸ë„ ì¤„ë°”ê¿ˆ ì²˜ë¦¬
            if len(summary_text) > 100:
                sentences = summary_text.split('. ')
                for sentence in sentences:
                    if sentence.strip():
                        print(f"   {sentence.strip()}{'.' if not sentence.endswith('.') else ''}")
            else:
                print(f"   {summary_text}")
            
            # 6. JSON íŒŒì¼ë¡œ ì €ì¥ (ì œí’ˆ ì •ë³´ì™€ ë¦¬ë·° ë¶„ë¦¬)
            product_code = product_info.get('product_code', 'unknown')
            timestamp = time.strftime('%Y%m%d_%H%M%S')
            
            if args.output:
                base_name = args.output.replace('.json', '')
            else:
                base_name = f"{product_code}_{timestamp}"
            
            # ì œí’ˆ ì •ë³´ë§Œ ì €ì¥
            info_file = f"info_{base_name}.json"
            info_data = {
                'product_info': {
                    'product_name': product_info.get('product_name', ''),
                    'product_code': product_info.get('product_code', ''),
                    'product_url': product_info.get('product_url', ''),
                    'category': product_info.get('category', ''),
                    'sub_category': product_info.get('sub_category', ''),
                    'price': product_info.get('price', ''),
                    'current_price': product_info.get('current_price', ''),
                    'discount_rate': product_info.get('discount_rate', ''),
                    'rating': product_info.get('rating', ''),
                    'review_count': product_info.get('review_count', ''),
                    'price_range': product_info.get('price_range', ''),
                    'usage_method': product_info.get('usage_method', ''),
                    'ingredients': product_info.get('ingredients', ''),
                    'precautions': product_info.get('precautions', ''),
                    'crawled_at': time.strftime('%Y-%m-%d %H:%M:%S')
                },
                'statistics': {
                    'total_reviews': len(reviews),
                    'average_rating': summary_data.get('average_rating', 0),
                    'positive_count': summary_data.get('positive_count', 0),
                    'negative_count': summary_data.get('negative_count', 0)
                },
                'summary': {
                    'summary_text': summary_data.get('summary', ''),
                    'key_points': summary_data.get('key_points', [])
                }
            }
            
            with open(info_file, 'w', encoding='utf-8') as f:
                json.dump(info_data, f, ensure_ascii=False, indent=2)
            
            # ë¦¬ë·°ë§Œ ì €ì¥
            review_file = f"review_{base_name}.json"
            reviews_data = []
            for review in reviews:
                review_data = {
                    'product_code': product_code,
                    'product_name': product_info.get('product_name', ''),
                    'username': review.get('username', ''),
                    'user_info': review.get('user_info', ''),
                    'age': review.get('age', ''),
                    'gender': review.get('gender', ''),
                    'skin_type_1': review.get('skin_type_1', ''),
                    'skin_type_2': review.get('skin_type_2', ''),
                    'rating': review.get('rating'),
                    'option': review.get('option', ''),
                    'review_type': review.get('review_type', ''),
                    'special_note_1': review.get('special_note_1', ''),
                    'special_note_2': review.get('special_note_2', ''),
                    'special_note_3': review.get('special_note_3', ''),
                    'review_text': review.get('review_text', '')
                }
                reviews_data.append(review_data)
            
            review_output = {
                'product_code': product_code,
                'product_name': product_info.get('product_name', ''),
                'total_reviews': len(reviews),
                'reviews': reviews_data,
                'crawled_at': time.strftime('%Y-%m-%d %H:%M:%S')
            }
            
            with open(review_file, 'w', encoding='utf-8') as f:
                json.dump(review_output, f, ensure_ascii=False, indent=2)
            
            print("\n" + "=" * 60)
            print("JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ")
            print("=" * 60)
            print(f"ğŸ“ ì œí’ˆ ì •ë³´: {info_file}")
            print(f"   - íŒŒì¼ í¬ê¸°: {os.path.getsize(info_file) / 1024:.2f} KB")
            print(f"ğŸ“ ë¦¬ë·°: {review_file}")
            print(f"   - ì´ {len(reviews)}ê°œ í›„ê¸°")
            print(f"   - íŒŒì¼ í¬ê¸°: {os.path.getsize(review_file) / 1024:.2f} KB")
            print("=" * 60)
            print("ì™„ë£Œ!")
            print("=" * 60)
        
    except Exception as e:
        print(f"\nì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        crawler.close()
        db.close()


if __name__ == "__main__":
    main()

